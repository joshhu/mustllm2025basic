{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md9CyZx52OE4"
      },
      "source": [
        "# Fine-tuning a model with the Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Transformers 提供了一個`Trainer`類別來**微調**資料集上提供的任何預訓練模型。完成資料預處理工作後，只需執行幾個步驟即可定義Trainer, 準備運行環境`Trainer.train()`"
      ],
      "metadata": {
        "id": "NPq1TS563uwp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84BvV60Q2OE6"
      },
      "source": [
        "安裝套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aj8MKXg2OE7"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cju0jFH72OE7"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(tokenized_datasets['train']['sentence1'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg6pYd7V-6pw",
        "outputId": "501e13db-d54d-4a91-fc27-2b1696f54c7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(tokenized_datasets['train']['sentence2'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zu0QCICAcv0",
        "outputId": "9ab88824-6637-4dee-acf5-bbe974fbd18c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7727, 2000, 2032, 2004, 2069, 1000, 1996, 7409, 1000, 1010, 2572, 3217, 5831, 5496, 2010, 2567, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNCgXweSA7KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(tokenized_datasets['train']['sentence1'][0], tokenized_datasets['train']['sentence2'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY673DXfAz5o",
        "outputId": "d157a599-4e6c-4d97-feaf-1cb45f4fbb1f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102, 7727, 2000, 2032, 2004, 2069, 1000, 1996, 7409, 1000, 1010, 2572, 3217, 5831, 5496, 2010, 2567, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train']['input_ids'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrc7Z87kAhRj",
        "outputId": "802a93aa-1cc2-4261-f76d-a6c2293db361"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2572,\n",
              " 3217,\n",
              " 5831,\n",
              " 5496,\n",
              " 2010,\n",
              " 2567,\n",
              " 1010,\n",
              " 3183,\n",
              " 2002,\n",
              " 2170,\n",
              " 1000,\n",
              " 1996,\n",
              " 7409,\n",
              " 1000,\n",
              " 1010,\n",
              " 1997,\n",
              " 9969,\n",
              " 4487,\n",
              " 23809,\n",
              " 3436,\n",
              " 2010,\n",
              " 3350,\n",
              " 1012,\n",
              " 102,\n",
              " 7727,\n",
              " 2000,\n",
              " 2032,\n",
              " 2004,\n",
              " 2069,\n",
              " 1000,\n",
              " 1996,\n",
              " 7409,\n",
              " 1000,\n",
              " 1010,\n",
              " 2572,\n",
              " 3217,\n",
              " 5831,\n",
              " 5496,\n",
              " 2010,\n",
              " 2567,\n",
              " 1997,\n",
              " 9969,\n",
              " 4487,\n",
              " 23809,\n",
              " 3436,\n",
              " 2010,\n",
              " 3350,\n",
              " 1012,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定義`Trainer`的參數\n",
        "我們定義我們之前的第一步`Trainer`是定義一個類別，其中包含將用於訓練和評估的`TrainingArguments`所有超參數。為求簡單，這邊`Trainer`提供的參數是儲存訓練模型的目錄以及訓練的輪數。對於其餘所有內容，保留預設值，這對於基本的微調應該非常有效。"
      ],
      "metadata": {
        "id": "cEr66md9BWgC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "695Hdu7z2OE8"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\", num_train_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用`AutoModelForSequenceClassification`有兩個標籤的類別"
      ],
      "metadata": {
        "id": "euE6S2KRC6NZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kMEg7Tay2OE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f347e50-c749-43cc-fb83-dc94e5c94cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 說明\n",
        "在實例化這個預訓練模型後會收到一個警告。這是因為BERT沒有在對句子對進行分類的任務上進行預訓練，因此預訓練模型的頭部被丟棄了(bert-base-uncase)，並且加入了一個適合序列分類的新頭部。表示有些權重未被使用（對應於被丟棄的預訓練頭部的那些）以及一些其他權重是隨機初始化的（新頭部）"
      ],
      "metadata": {
        "id": "NwdwdP-hFERI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定義`Trainer`\n",
        "有了模型，就可以傳入建構的所有對象來定義一個訓練器模型、`training_args`、訓練和驗證資料集、`data_collator`和分詞器"
      ],
      "metadata": {
        "id": "vDcNOuWJFeIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4d9isgES2OE8"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 說明\n",
        "這樣傳遞分詞器時，訓練器使用的預設`data_collator`將是之前定義的`DataCollatorWithPadding`，因此可以跳過`data_collator=data_collator`這一行"
      ],
      "metadata": {
        "id": "PvjNn8H2F445"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 開始訓練\n",
        "呼叫`Trainer`中的`train()`方法"
      ],
      "metadata": {
        "id": "R-rqrmewGEEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TqWauJqE2OE9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "1f8c036a-01cc-4229-d0e6-01554d7f8abe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4590' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4590/4590 05:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.572100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.534300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.362100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.240100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.026500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4590, training_loss=0.21945529145093265, metrics={'train_runtime': 312.5812, 'train_samples_per_second': 117.346, 'train_steps_per_second': 14.684, 'total_flos': 1353042435523440.0, 'train_loss': 0.21945529145093265, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 改進的地方\n",
        "開始微調之後並每500步報告一次訓練損失。但不會知道模型的表現如何，因為有幾個原因\n",
        "* 沒有設定`evaluation_strategy`為`steps`（每`eval_steps`評估一次）或`epoch`（在每個`epoch`結束時評估）來告訴訓練器在訓練期間進行評估\n",
        "* 沒有為訓練器提供`compute_metrics()`函數，在上述評估期間計算指標"
      ],
      "metadata": {
        "id": "Q4230l-IGOr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 對模型這行評估\n",
        "使用validation資料集，讓資料集通過訓練好的模型。由於validation資料中有408筆資料，每筆資料經過模型之後，會有兩個logits，所以是408x2個。第一個是label為0的浮點數，第二個是label為1的浮點數，較大的值對應到模型預測出來可能性較高的結果。\n",
        "\n",
        "另外`labels.ids`就是ground true真值，不是0就是1，所以也有408x1個"
      ],
      "metadata": {
        "id": "RYoeNstKHVM8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GPGU9A7m2OE9",
        "outputId": "aabc04e2-01af-4359-8e1f-dd83c8525fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(408, 2) (408,)\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.predictions[0])\n",
        "print(predictions.label_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC7ad-I-IQFv",
        "outputId": "79623c74-0950-41ee-d61a-0e63935ea830"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.7432883  3.6470644]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "也可以用softmax表示"
      ],
      "metadata": {
        "id": "OEAn6Jx1JOPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Defining the softmax function\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))  # Subtracting the max for numerical stability\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "# Input array\n",
        "x = np.array(predictions.predictions[0])\n",
        "\n",
        "# Applying the softmax function\n",
        "softmax_values = softmax(x)\n",
        "softmax_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNqINNueJNpw",
        "outputId": "73a09ac2-78b2-4e0f-bb2d-dc40e911e06e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.1679754e-04, 9.9938321e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x_tensor = torch.tensor(predictions.predictions[0])\n",
        "softmax_values_torch = F.softmax(x_tensor, dim=0)\n",
        "softmax_values_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lam3IpSKIzv",
        "outputId": "9d17efc8-7908-4375-a899-d17ddfc4d781"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.1680e-04, 9.9938e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict() 方法的輸出是另一個命名組合，包含三個欄位：predictions、label_ids 和 metrics。metrics 欄位將只包含傳遞的資料集上的損失，以及一些時間度量（預測所需的總時間和平均時間）。一旦完成我們的 compute_metrics() 函式並將其傳遞給 Trainer，該欄位也將包含 compute_metrics() 返回的度量。\n",
        "\n",
        "predictions 是一個形狀為 408 x 2 的二維陣列（408 是我們使用的資料集中的元素數量）。這些是我們傳遞給 predict() 的資料集中每個元素的 logits, 所有 Transformer 模型都返回 logits）。為了將它們轉換成我們可以與我們的標籤比較的預測，我們需要取第二軸上最大值的索引"
      ],
      "metadata": {
        "id": "IRUHtrJwK4kp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "z3-9bVzX2OE9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"預測：\", preds[:20])\n",
        "print(\"真值：\", predictions.label_ids[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaTnJIkfLJLI",
        "outputId": "61d53e1c-304f-44ab-c0d3-6e1c6fcdc6ce"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "預測： [1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0]\n",
            "真值： [1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 計算模型表現的度量方法\n",
        "有很多種度量模型表現的指標，如408個預測中，有幾個是和直值一模一樣的，然後算出不一樣的比例，這種稱為accuracy，也有其它的度量方法，如f1 score等等。針對不同資料集，會有不同的度量方法，我們只要載入那個資料集對對的度量方法即可。"
      ],
      "metadata": {
        "id": "4u1EL6ImL5Zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用`Evaluate` 函式庫的度量。我們可以像載入資料集一樣輕鬆地載入與 MRPC 資料集相關的度量，這次使用 `evaluate.load()` 函式。返回的物件有一個 `compute()` 方法，使用它來進行度量計算："
      ],
      "metadata": {
        "id": "rQGGVLwSMXAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "wXIXK7KI2OE-",
        "outputId": "b1ad8432-d909-4a0e-d126-1539a47f8beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8602941176470589, 'f1': 0.9025641025641027}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義一個`compute_metrics()`方法作為參數傳入`Trainer`的物件，就可以在訓練時列出每一個階段的accuracy和f1 score了。"
      ],
      "metadata": {
        "id": "1fsxXQRqM5H9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eOEedZn82OE-"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "rfv8rAdk2OE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1c1350-e10e-4642-e9a3-e67a7886ccf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\", num_train_epochs=10)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "jbHi-oIO2OE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "cf5d3903-4ae2-4e1d-de63-1b4dbbbbcb76"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4590' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4590/4590 05:37, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.624463</td>\n",
              "      <td>0.683824</td>\n",
              "      <td>0.812227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.636500</td>\n",
              "      <td>0.633032</td>\n",
              "      <td>0.683824</td>\n",
              "      <td>0.812227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.621100</td>\n",
              "      <td>0.657776</td>\n",
              "      <td>0.632353</td>\n",
              "      <td>0.682203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.589100</td>\n",
              "      <td>0.572164</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.523600</td>\n",
              "      <td>0.628840</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>0.853933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.712520</td>\n",
              "      <td>0.806373</td>\n",
              "      <td>0.864028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.275900</td>\n",
              "      <td>0.810928</td>\n",
              "      <td>0.806373</td>\n",
              "      <td>0.865417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.180700</td>\n",
              "      <td>0.903257</td>\n",
              "      <td>0.806373</td>\n",
              "      <td>0.868114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.105600</td>\n",
              "      <td>1.009090</td>\n",
              "      <td>0.808824</td>\n",
              "      <td>0.865979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.069800</td>\n",
              "      <td>1.031263</td>\n",
              "      <td>0.818627</td>\n",
              "      <td>0.876667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4590, training_loss=0.3699027975660004, metrics={'train_runtime': 338.0971, 'train_samples_per_second': 108.49, 'train_steps_per_second': 13.576, 'total_flos': 1353042435523440.0, 'train_loss': 0.3699027975660004, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iy26ygWCT1cq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}